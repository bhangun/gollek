# LibTorch Provider Configuration
# ================================
# Disabled by default â€” enable when libtorch native libraries are available
libtorch.provider.enabled=false

# Native library path
# Default: searches Inference-golek-vendor/libtorch/libtorch-{platform}/lib,
# then LIBTORCH_PATH env var, then system library path
# libtorch.provider.native-lib.library-path=

# Model configuration
libtorch.provider.model.base-path=${user.home}/.golek/models/torchscript
libtorch.provider.model.extensions=.pt,.pts,.pth

# GPU/CUDA configuration
libtorch.provider.gpu.enabled=false
libtorch.provider.gpu.device-index=0

# Session pool configuration
libtorch.provider.session.max-per-tenant=4
libtorch.provider.session.idle-timeout-seconds=300
libtorch.provider.session.max-total=16

# Inference configuration
libtorch.provider.inference.timeout-seconds=30
libtorch.provider.inference.threads=4
