# Ollama Provider

Provider for local Ollama inference.

## Key Capabilities

* Local model execution via Ollama server
* Streaming inference
* Simple local deployment
